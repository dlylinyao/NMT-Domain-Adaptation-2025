{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14414569,"sourceType":"datasetVersion","datasetId":9206452},{"sourceId":14433029,"sourceType":"datasetVersion","datasetId":9218849},{"sourceId":14433570,"sourceType":"datasetVersion","datasetId":9219223},{"sourceId":14433942,"sourceType":"datasetVersion","datasetId":9219489}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install -q sacrebleu unbabel-comet transformers[torch] datasets evaluate sentencepiece\n\n# Standard Library Imports\nimport os\nimport math\nimport random\nimport shutil\nfrom collections import Counter\n\n# Data Processing & Math\nimport numpy as np\nimport pandas as pd\nimport torch\n\n# Hugging Face Libraries\nimport evaluate\nfrom datasets import Dataset\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n)\n\n# Comet Library\nfrom comet import download_model, load_from_checkpoint\n\nprint(\"Environment setup and imports completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:50:34.698175Z","iopub.execute_input":"2026-01-08T16:50:34.698787Z","iopub.status.idle":"2026-01-08T16:51:01.199230Z","shell.execute_reply.started":"2026-01-08T16:50:34.698758Z","shell.execute_reply":"2026-01-08T16:51:01.197513Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngrain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 4.25.8 which is incompatible.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\njaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\njax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2026-01-08 16:50:49.612905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767891049.823990      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767891049.878918      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767891050.389347      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767891050.389392      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767891050.389397      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767891050.389401      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3483587843.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Hugging Face Libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m from transformers import (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluation_suite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluationSuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .evaluator import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mAudioClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/evaluation_suite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation_module_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/evaluator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSUPPORTED_TASKS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSUPPORTED_PIPELINE_TASKS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTASK_ALIASES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_task\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcheck_pipeline_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_module_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFEATURE_EXTRACTOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_processing_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_image_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf_keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_tf_keras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/_tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/_tf_keras/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/visualization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_bounding_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_image_gallery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/visualization/draw_bounding_boxes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OpenCV bindings requires \"numpy\" package.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_from_c_func_and_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/overrides.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(dispatcher)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/overrides.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(implementation)\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: empty_like method already has a different docstring"],"ename":"RuntimeError","evalue":"empty_like method already has a different docstring","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# import os\n# import math\n# import random\n# from collections import Counter\n\nPOSSIBLE_PATHS = [\n    \"/kaggle/input/final-data/processed\", \n    \"/kaggle/input/final-data\", \n    \"/kaggle/input/processed\"\n]\nDATA_DIR = None\nfor p in POSSIBLE_PATHS:\n    if os.path.exists(p) and \"train_unpc.en\" in os.listdir(p):\n        DATA_DIR = p\n        break\n\nif not DATA_DIR:\n    print(\"Data path not found. Please manually modify the DATA_DIR variable!\")\nelse:\n    print(f\"Data Directory: {DATA_DIR}\")\n\ndef analyze_corpus(name, src_filename, tgt_filename):\n    src_path = os.path.join(DATA_DIR, src_filename)\n    tgt_path = os.path.join(DATA_DIR, tgt_filename)\n    \n    if not os.path.exists(src_path) or not os.path.exists(tgt_path):\n        print(f\"⚠️ Skipping {name}: File not found\")\n        return\n\n    print(f\"\\n======== Analyzing: {name} ========\")\n    \n    # Statistical variables\n    src_lines, tgt_lines = [], []\n    src_lens_char, tgt_lens_char = [], []\n    src_lens_word, tgt_lens_word = [], []\n    src_vocab, tgt_vocab = set(), set()\n    \n    # Read Source\n    with open(src_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            l = line.strip()\n            src_lines.append(l)\n            src_lens_char.append(len(l))\n            words = l.split() # Simple whitespace tokenization\n            src_lens_word.append(len(words))\n            src_vocab.update(words)\n\n    # Read Target\n    with open(tgt_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            l = line.strip()\n            tgt_lines.append(l)\n            tgt_lens_char.append(len(l))\n            words = l.split()\n            tgt_lens_word.append(len(words))\n            tgt_vocab.update(words)\n\n    count = len(src_lines)\n    print(f\"1. Line Count (Sentence Pairs): {count}\")\n    \n    avg_src_w = sum(src_lens_word) / count\n    avg_tgt_w = sum(tgt_lens_word) / count\n    avg_src_c = sum(src_lens_char) / count\n    avg_tgt_c = sum(tgt_lens_char) / count\n    \n    print(f\"2. Avg Length (Source EN): {avg_src_w:.2f} words, {avg_src_c:.2f} chars\")\n    print(f\"   Avg Length (Target ZH): {avg_tgt_w:.2f} words, {avg_tgt_c:.2f} chars\")\n\n    print(f\"3. Vocabulary Size (Unique Tokens): Source={len(src_vocab)}, Target={len(tgt_vocab)}\")\n\n    ratios = []\n    for sl, tl in zip(src_lens_char, tgt_lens_char):\n        if tl == 0: continue\n        ratios.append(sl / tl)\n    if ratios:\n        avg_ratio = sum(ratios) / len(ratios)\n        print(f\"4. Avg Length Ratio (Src/Tgt Char Ratio): {avg_ratio:.2f}\")\n\n    def get_entropy(text_list):\n        full_text = \"\".join(text_list)\n        if not full_text: return 0\n        counts = Counter(full_text)\n        total = len(full_text)\n        ent = 0\n        for cnt in counts.values():\n            p = cnt / total\n            ent -= p * math.log2(p)\n        return ent\n\n    print(\"5. Calculating Character Entropy...\")\n    print(f\"   Source Entropy: {get_entropy(src_lines):.4f}\")\n    print(f\"   Target Entropy: {get_entropy(tgt_lines):.4f}\")\n\n    print(\"\\n----- Random Sample (Qualitative Check) -----\")\n    indices = random.sample(range(count), min(20, count))\n    for idx in indices:\n        print(f\"[{idx}] EN: {src_lines[idx]}\")\n        print(f\"      ZH: {tgt_lines[idx]}\")\n\nif DATA_DIR:\n    # Analyze UNPC Cleaned\n    analyze_corpus(\"UNPC Cleaned (Train)\", \"train_unpc.en\", \"train_unpc.zh\")\n    \n    # Analyze TED Cleaned\n    analyze_corpus(\"TED Cleaned (Train)\", \"train_ted.en\", \"train_ted.zh\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T10:08:01.460830Z","iopub.execute_input":"2026-01-08T10:08:01.461588Z","iopub.status.idle":"2026-01-08T10:08:11.410917Z","shell.execute_reply.started":"2026-01-08T10:08:01.461557Z","shell.execute_reply":"2026-01-08T10:08:11.410144Z"}},"outputs":[{"name":"stdout","text":"Data Directory: /kaggle/input/final-data/processed\n\n======== Analyzing: UNPC Cleaned (Train) ========\n1. Line Count (Sentence Pairs): 462483\n2. Avg Length (Source EN): 19.45 words, 123.11 chars\n   Avg Length (Target ZH): 2.81 words, 49.63 chars\n3. Vocabulary Size (Unique Tokens): Source=372300, Target=669711\n4. Avg Length Ratio (Src/Tgt Char Ratio): 2.42\n5. Calculating Character Entropy...\n   Source Entropy: 4.8487\n   Target Entropy: 8.5990\n\n----- Random Sample (Qualitative Check) -----\n[235377] EN: (d) Human rights and disability;\n      ZH: (d) 人权与残疾问题；\n[401839] EN: The Council then proceeded to the vote on the draft resolution before it (S/2000/1124).\n      ZH: 安理会接着就面前的决议草案（S/2000/1124）进行表决。\n[422352] EN: B. Organization of UNISPACE III\n      ZH: B. 第三次外空会议的安排\n[293831] EN: In May 1999, UNFPA approved its first project for the former Yugoslav Republic of Macedonia, including an initial amount of $5,000 earmarked for technical needs assessment.\n      ZH: 1999年5月,人口基金核准了其援助前南斯拉夫的马其顿共和国的第一个项目,包括专门拨给用于技术需求评估的初期资金5 000美元。\n[77094] EN: The Working Group met again in May and June 2001 to focus on conflict prevention, post-conflict peace-building and education.\n      ZH: 工作组于2001年5月和6月再次开会，集中讨论预防冲突、冲突后的和平建设和教育问题。\n[151171] EN: 8. Mr. Jaremczuk (Poland), Mr. Bliznikas (Lithuania) and Mr. Stanescu (Romania) said that their delegations wished to align themselves with the statement made by the representative of Austria on behalf of the European Union.\n      ZH: 8. Jaremczuk先生(波兰)、Bliznikas先生(立陶宛)和Stanescu先生(罗马尼亚)说,他们的代表希望赞同奥地利代表,代表欧洲联盟的名义所作的发言。\n[45023] EN: Cyprus has faced the HIV/AIDS problem since 1986, but remains a low-prevalence country.\n      ZH: 塞浦路斯自1986年起面临艾滋病毒/艾滋病问题，但一直是低发病国家。\n[21954] EN: C. Communications received from 20 June 2000 to 15 June 2001 and reports of the Secretary-General\n      ZH: C. 2000年6月20日至2001年6月15日收到的来 文和秘书长的报告\n[263373] EN: 175. Institutional infrastructure.\n      ZH: 175. 体制基础设施。\n[394512] EN: Typically, the well will produce from one zone inside a production &quot; string &quot; or tube inside the casing, and from the other zone oil will be produced in the area between the production string and the casing (known as the &quot; annulus &quot; ).\n      ZH: 油井通常从一个区的油层 &quot; 套管 &quot; ，即套管中的管道采油，而另一个区则从油层套管和钻井套管之间的区域(称为 &quot; 环带 &quot; )采油。\n[310782] EN: It was so decided.\n      ZH: 5. 会议决定如上。\n[66498] EN: Panel discussion: “Criteria to test the development friendliness of international investment agreements”\n      ZH: 小组讨论： &quot; 用来检验国际投资协定助益发展程度的标准 &quot;\n[411646] EN: 2.2 At around 4 a.m. on 10 January 1988, Antonio Rodríguez Cottin was stabbed five times in a car lot outside a discotheque in Mocejón, Toledo.\n      ZH: 2.2. 1988年1月10日大约早上4点，Antonio Rodríguez Cottin在Toledo Mocejon一迪斯科舞厅外的停车处被捅了五刀。\n[395190] EN: In this respect, Indonesia received the visit of the Special Rapporteur on Torture in 1991, the Special Rapporteur on Summary or Arbitrary Executions in 1994 and, in 1995, the highest authority in the field of human rights, the High Commissioner.\n      ZH: 在此方面，印度尼西亚于1991年接待了酷刑问题特别报告员的来访，于1994年接待了即决处决或任意处决问题报告员的来访并于1995年接待了高级专员这一人权领域中最高权威的来访。\n[112584] EN: Sen describes this matching in terms of the Kantian concept of &quot; perfect obligation &quot; .\n      ZH: 阿马蒂亚·森用康德的 &quot; 绝对义务 &quot; 来描述这种匹配。\n[27149] EN: Number of refugees assisted to return.\n      ZH: 为返回而得到协助的难民人数。\n[304637] EN: It will include, inter alia, representatives of the Department for Disarmament Affairs, the Office for the Coordination of Humanitarian Affairs, UNHCR, UNICEF, UNDP, UNOPS, WFP, FAO, the World Bank and WHO.\n      ZH: 该组包括下列组织的代表：裁军事务部、人道主义事务协调厅、难民专员办事处、儿童基金会、开发计划署、项目厅、粮食计划署、粮农组织、世界银行和卫生组织。\n[415798] EN: In subparagraph (b), in the last sentence, after the words &quot; and sensitizing policy makers &quot; , insert the words &quot; and more importantly, local communities at the grass-roots level &quot; ; and after the words &quot; HIV/AIDS &quot; , replace the word &quot; epidemic &quot; with the words &quot; and other epidemics, such as malaria &quot; .\n      ZH: 在（b）分段最后一句中，在 &quot; 使决策者了解 &quot; 后插入 &quot; ，更重要的是，使基层的地方社区了解 &quot; ；并在 &quot; 艾滋病毒/艾滋病 &quot; 的后面插入 &quot; 以及如虐疾等其他流行病 &quot; 。\n[111031] EN: Decision 1 (53) on Australia 18\n      ZH: 关于澳大利亚的第1(53)号决定. 19\n[55919] EN: Yet this is obviously not the case.\n      ZH: 然而,事实显然不是这样。\n\n======== Analyzing: TED Cleaned (Train) ========\n1. Line Count (Sentence Pairs): 50000\n2. Avg Length (Source EN): 15.77 words, 87.08 chars\n   Avg Length (Target ZH): 2.35 words, 35.95 chars\n3. Vocabulary Size (Unique Tokens): Source=65426, Target=109915\n4. Avg Length Ratio (Src/Tgt Char Ratio): 2.44\n5. Calculating Character Entropy...\n   Source Entropy: 4.5101\n   Target Entropy: 8.8156\n\n----- Random Sample (Qualitative Check) -----\n[32625] EN: Now I'd like to say I woke up one morning and said, \"I'm going to write about collaborative consumption,\" but actually it was a complicated web of seemingly disconnected ideas.\n      ZH: 其实我是很想这么说，“有天早上，我刚醒就觉得， 关于协作消费，我得写点什么东西。” 不过事实上这想法是一个复杂网络， 它看似由一些风马牛不相及的想法构成。\n[3226] EN: She goes village to village doing screenings.\n      ZH: 因为她会奔波于好几个村落之间进行检测\n[35242] EN: And you can show, just by looking at data from literature, that vector-borne diseases are more harmful than non-vector-borne diseases.\n      ZH: 而且，仅仅通过查看文献中的数据，你就会发现 通过虫媒传播的疾病比那些 通过非虫媒传播的疾病更加有害。\n[33634] EN: \"Got something on my hair?\" Here we go. Alright.\n      ZH: “还是我头发沾上什么东西了?” 嗯，就是这个。\n[3797] EN: But anyway, you know, I just think that to be here with all of you accomplished young people -- literally, some of you, the architects building our brighter future.\n      ZH: 好吧 不管怎样 我只是觉得 跟你们在一起 跟你们这些年轻人在一起 而且你们当中有些是建筑师 就是要搭建我们更美好的未来的\n[28025] EN: We finally, after 40 years of knowing that wholegrain was a healthier option, we're finally getting to the point where we actually are tipping over and attempting to actually eat them.\n      ZH: 如今，在我们40年前便已知道 全麦面包要更加健康的情况下， 终于到取得重大突破的时候了， 我们终于有机会真正去吃全麦面包了。\n[39251] EN: http://www.ted.com/talks/kathryn_schulz_don_t_regret_regret.html\n      ZH: http://www.ted.com/talks/lang/zh-cn/kathryn_schulz_don_t_regret_regret.html\n[25688] EN: So I put it through a G.C., a Gas Chromatograph that I have in my office, and it’s about 400.\n      ZH: 于是 我用我办公室里的气相色谱仪做了一下检测 发现大约有400个\n[16921] EN: It has floated away down a dark mythological river whose name begins with an L as far as you can recall, well on your own way to oblivion where you will join those who have forgotten even how to swim and how to ride a bicycle.\n      ZH: 它已漂走了， 顺着神话中的黑暗河流。 你只能回忆起它的名字以L开始。 剩下的你记不起来了。 就在你通往遗忘的路上， 你将加入那些 甚至忘记了如何游泳 和骑自行车的人们。\n[43263] EN: And they were to blow up strategic targets and take over the country, and they were foiled by a Nigerian James Bond called Coyote Williams, and a Jewish Nazi hunter.\n      ZH: 他们突然打击战略目标 掌握了整个国家，结果被一个人阻止了， 这人是一个尼日利亚的詹姆士.邦德，名叫考尔欧特.威廉姆斯. 和一个犹太人——一个犹太的“纳粹猎人”。\n[19119] EN: But whoever decided that a chicken should look like a heart, a giraffe, a star?\n      ZH: 又是谁决定了鸡应该长什么样， 心形，长颈鹿形，或是星形？\n[19399] EN: And I actually said at one conference a couple of years ago, \"Give me my damn data, because you people can't be trusted to keep it clean.\"\n      ZH: 我实际上在几年之前在一个会议上说到， 给我该死的数据， 因为你们这些人不能被信任，让这些数据清楚明白。\n[43430] EN: With PISA, we wanted to measure how they actually deliver equity, in terms of ensuring that people from different social backgrounds have equal chances.\n      ZH: 我们就用PISA来测试他们是如何做到教育公平， 也就是如何确保学生 无论其来自哪种不同的社会背景都有均等的受教育机会。\n[1198] EN: And we're now going to put some chemistry inside and do some chemistry in this cell.\n      ZH: 我们准备在里面放上一些化学物质，并在细胞内进行一些化学反应。\n[27825] EN: You get swine flu in Mexico, it's a problem for Charles de Gaulle Airport 24 hours later.\n      ZH: 你在墨西哥染上猪流感 24 小时后，它便成为 戴高乐机场的问题\n[37675] EN: I know I've talked about Agnes here before, but I want to give you an update on Agnes.\n      ZH: 我知道我以前在这里已经说过关于艾格尼丝的事情了 但现在我要告诉你们一些她的最新消息\n[48084] EN: And more importantly, that line between good and evil -- which privileged people like to think is fixed and impermeable, with them on the good side, and the others on the bad side -- I knew that line was movable, and it was permeable.\n      ZH: 更重要的是，善恶之间的界限—— 特权阶层喜欢认定这个界限是固定且不可逾越的， 认为他们是在善的一边，其他人在恶的一边—— 而我以前就知道这个界限是可以移动的，而且是可逾越的。\n[15910] EN: That's in order to delay -- until act five, he can kill him.\n      ZH: 这一切都是为了推迟——直到在第五幕他杀掉他叔叔。\n[21942] EN: In 2005, remittances -- I just took one country, Nigeria skyrocketing -- skyrocketing is too dramatic, but increasing dramatically.\n      ZH: 2005年， 汇款--拿尼日利亚作例子-- 你们知道，那是飞速上升-说飞速上升那就发展得太快了 但的确增长地非常快\n[29804] EN: June Cohen: Frank, that was beautiful, so touching.\n      ZH: 琼·科恩:弗兰克,那太美妙了 真的很感人\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!pip install -q transformers[torch] datasets sacrebleu evaluate sentencepiece\n\n#import torch\n\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"Current Device: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"Warning: You are using CPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T10:08:11.412258Z","iopub.execute_input":"2026-01-08T10:08:11.412522Z","iopub.status.idle":"2026-01-08T10:08:17.647005Z","shell.execute_reply.started":"2026-01-08T10:08:11.412499Z","shell.execute_reply":"2026-01-08T10:08:17.646247Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hGPU Available: True\nCurrent Device: Tesla T4\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Tokenizer Analysis & Data Path Verification\n#import os\n#import numpy as np\n#from transformers import AutoTokenizer\n\nPOSSIBLE_PATHS = [\n    \"/kaggle/input/final-data/processed\", \n    \"/kaggle/input/final-data\",          \n    \"/kaggle/input/processed\"            \n]\n\nDATA_DIR = None\nfor p in POSSIBLE_PATHS:\n    if os.path.exists(p) and \"train_unpc.en\" in os.listdir(p):\n        DATA_DIR = p\n        break\n\nif not DATA_DIR:\n    print(\"Data not found! Please check the Data panel on the right, copy the 'processed' folder path, and update the paths above.\")\nelse:\n    print(f\"Data path confirmed: {DATA_DIR}\")\n\nMODEL_CHECKPOINT = \"Helsinki-NLP/opus-mt-en-mul\"\n\n# Load Tokenizer\nprint(f\"Loading model vocabulary: {MODEL_CHECKPOINT}...\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n\ndef analyze_file(filename, label):\n    filepath = os.path.join(DATA_DIR, filename)\n    print(f\"\\n Analyzing: {label} ({filename})\")\n    \n    lengths = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(f):\n            if i >= 10000: break \n            tokens = tokenizer.tokenize(line.strip())\n            lengths.append(len(tokens))\n            \n            if i < 2:\n                print(f\"  [Sample {i+1}] Text: {line.strip()[:50]}...\")\n                print(f\"  [Sample {i+1}] Tokens: {tokens}\")\n\n    print(f\" {label} Average Length: {np.mean(lengths):.2f} tokens\")\n\n# Run Analysis\nif DATA_DIR:\n    analyze_file(\"train_unpc.en\", \"English Train Set\")\n    analyze_file(\"train_unpc.zh\", \"Chinese Train Set\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T10:08:21.648756Z","iopub.execute_input":"2026-01-08T10:08:21.649418Z","iopub.status.idle":"2026-01-08T10:08:24.677122Z","shell.execute_reply.started":"2026-01-08T10:08:21.649372Z","shell.execute_reply":"2026-01-08T10:08:24.676336Z"}},"outputs":[{"name":"stdout","text":"Data path confirmed: /kaggle/input/final-data/processed\nLoading model vocabulary: Helsinki-NLP/opus-mt-en-mul...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65c32b5568754ec281c8c681b22eed74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e652a548db374a9e819ce19d4afa3b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/790k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d010482eff48ac8a91c2b9d71eddf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/707k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"231caa2b0e734763aa0e9d700c9196df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbb7786d948f425eb5164d0a68af378f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"name":"stdout","text":"\n Analyzing: English Train Set (train_unpc.en)\n  [Sample 1] Text: a 1999 data are provisional....\n  [Sample 1] Tokens: ['▁a', '▁1999', '▁data', '▁are', '▁provisional', '.']\n  [Sample 2] Text: Recalling its resolution 49/251 of 20 July 1995 on...\n  [Sample 2] Tokens: ['▁Recalling', '▁its', '▁resolution', '▁49', '/25', '1', '▁of', '▁20', '▁July', '▁1995', '▁on', '▁the', '▁financing', '▁of', '▁the', '▁Tribunal', '▁and', '▁its', '▁subsequent', '▁resolutions', '▁thereon', ',', '▁the', '▁latest', '▁of', '▁which', '▁was', '▁resolution', '▁53', '/21', '3', '▁of', '▁18', '▁December', '▁1998,']\n English Train Set Average Length: 27.84 tokens\n\n Analyzing: Chinese Train Set (train_unpc.zh)\n  [Sample 1] Text: a 1999年数据为暂定数据。...\n  [Sample 1] Tokens: ['▁a', '▁1999', '年', '数', '据', '为', '暂', '定', '数', '据', '。']\n  [Sample 2] Text: 回顾其1995年7月20日关于该法庭经费筹措的第49/251号决议及其后各项有关决议,最近的一项是1...\n  [Sample 2] Tokens: ['▁', '回', '顾', '其', '1995', '年', '7', '月', '20', '日', '关', '于', '该', '法', '庭', '经', '费', '筹措', '的', '第', '49', '/25', '1', '号', '决议', '及', '其', '后', '各', '项', '有', '关', '决议', ',', '最近', '的', '一', '项', '是', '1998', '年', '12', '月', '18', '日', '第', '53', '/21', '3', '号', '决议', ',']\n Chinese Train Set Average Length: 38.84 tokens\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Training\n#from datasets import Dataset\n#from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n#import evaluate\n#import numpy as np \n\n# Core Configuration \nSOURCE_PREFIX = \">>zho<< \" \nBATCH_SIZE = 16         \nLEARNING_RATE = 2e-5\nNUM_EPOCHS = 3       \nOUTPUT_DIR = \"/kaggle/working/unpc_model\"\n\ndef load_dataset_from_text(src_path, tgt_path):\n    with open(src_path, \"r\", encoding=\"utf-8\") as fs, open(tgt_path, \"r\", encoding=\"utf-8\") as ft:\n        return Dataset.from_dict({\"source\": [l.strip() for l in fs], \"target\": [l.strip() for l in ft]})\n\nprint(\"Loading training data...\")\ntrain_ds = load_dataset_from_text(os.path.join(DATA_DIR, \"train_unpc.en\"), os.path.join(DATA_DIR, \"train_unpc.zh\"))\ndev_ds = load_dataset_from_text(os.path.join(DATA_DIR, \"dev_unpc.en\"), os.path.join(DATA_DIR, \"dev_unpc.zh\"))\n\n# Data Preprocessing\ndef preprocess_function(examples):\n    inputs = [SOURCE_PREFIX + ex for ex in examples[\"source\"]]\n    targets = examples[\"target\"]\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\nprint(\"Preprocessing data (Tokenizing)...\")\ntokenized_train = train_ds.map(preprocess_function, batched=True)\ntokenized_dev = dev_ds.map(preprocess_function, batched=True)\n\n# Training Settings\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\nmetric = evaluate.load(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple): preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    \n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=OUTPUT_DIR,\n    eval_strategy=\"epoch\",    \n    # eval_steps=500,             \n    save_strategy=\"epoch\",\n    # save_steps=1000,            \n    learning_rate=LEARNING_RATE,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    save_total_limit=2,         \n    num_train_epochs=NUM_EPOCHS,\n    predict_with_generate=True, \n    fp16=True,                  \n    logging_steps=100,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_dev,\n    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Start Training\nprint(\"Starting training UNPC...\")\n#trainer.train()\ntrainer.train(resume_from_checkpoint=True)\n\n# Save final model\nfinal_path = \"/kaggle/working/final_unpc_model\"\ntrainer.save_model(final_path)\nprint(f\"Training complete! Model saved to: {final_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T11:43:38.384132Z","iopub.execute_input":"2026-01-07T11:43:38.384642Z"}},"outputs":[{"name":"stderr","text":"2026-01-07 11:43:41.167438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767786221.369427      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767786221.428992      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767786221.908493      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767786221.908536      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767786221.908539      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767786221.908542      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Loading training data...\nPreprocessing data (Tokenizing)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/462483 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02cb6d71a3024d58b11ee49a29512a81"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f241a7cbd104843859b9ec3f29700e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/310M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5dd8d7764745a4a7aceeaa2f483e6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b3d25b2cf14506b343baae7bce61cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/310M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97eded39b8e143e89cc7d5d7c0af2f0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c38b463d2f94d7292573e93413d0e62"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_55/3121990578.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n","output_type":"stream"},{"name":"stdout","text":"Starting training UNPC...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='11001' max='43359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [11001/43359 1:47:30 < 5:16:16, 1.71 it/s, Epoch 0.76/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.564900</td>\n      <td>1.414642</td>\n      <td>40.695424</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.537200</td>\n      <td>1.371690</td>\n      <td>41.939455</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.485500</td>\n      <td>1.344323</td>\n      <td>42.581711</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.494000</td>\n      <td>1.317937</td>\n      <td>42.573584</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.440300</td>\n      <td>1.304024</td>\n      <td>43.081414</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.451100</td>\n      <td>1.281759</td>\n      <td>42.164693</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.397200</td>\n      <td>1.271233</td>\n      <td>43.343915</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.394400</td>\n      <td>1.253204</td>\n      <td>43.990786</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.392100</td>\n      <td>1.242192</td>\n      <td>43.615113</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.364500</td>\n      <td>1.230039</td>\n      <td>43.906812</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.313500</td>\n      <td>1.222395</td>\n      <td>44.007063</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.336700</td>\n      <td>1.212390</td>\n      <td>43.377445</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.320200</td>\n      <td>1.199851</td>\n      <td>43.947655</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.321200</td>\n      <td>1.195669</td>\n      <td>44.080434</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.288100</td>\n      <td>1.184948</td>\n      <td>44.819466</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.321200</td>\n      <td>1.176350</td>\n      <td>44.902107</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.310000</td>\n      <td>1.172827</td>\n      <td>44.675221</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.291400</td>\n      <td>1.166699</td>\n      <td>45.009187</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.291800</td>\n      <td>1.159054</td>\n      <td>44.758682</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.272500</td>\n      <td>1.154482</td>\n      <td>45.250219</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.273900</td>\n      <td>1.149260</td>\n      <td>45.109394</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='29' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [29/32 01:22 < 00:08, 0.34 it/s]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[64109]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"#import os\n#import shutil\n\n\nmodel_path = \"/kaggle/working/final_unpc_model\"\noutput_filename = \"/kaggle/working/unpc_model_backup\"\n\nprint(\"Compressing model folder, please wait...\")\nshutil.make_archive(output_filename, 'zip', model_path)\nprint(f\"Compression complete! File created: {output_filename}.zip\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import os\n#import numpy as np\n#import evaluate\n#from datasets import Dataset\n#from transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n)\n#import shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T10:30:30.935862Z","iopub.execute_input":"2026-01-08T10:30:30.936498Z","iopub.status.idle":"2026-01-08T10:30:30.940131Z","shell.execute_reply.started":"2026-01-08T10:30:30.936464Z","shell.execute_reply":"2026-01-08T10:30:30.939473Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/final-data/processed\" \n\nCHECKPOINT_PATH = \"/kaggle/input/final-unpc-model\" \n\nOUTPUT_DIR = \"/kaggle/working/final_ted_model\"\n\ndef load_dataset_from_text(src_path, tgt_path):\n    with open(src_path, \"r\", encoding=\"utf-8\") as fs, open(tgt_path, \"r\", encoding=\"utf-8\") as ft:\n        return Dataset.from_dict({\"source\": [l.strip() for l in fs], \"target\": [l.strip() for l in ft]})\n\nSOURCE_PREFIX = \">>zho<< \"\n\ndef preprocess_function(examples):\n    inputs = [SOURCE_PREFIX + ex for ex in examples[\"source\"]]\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples[\"target\"], max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple): preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n\nprint(f\"Loading Pre-trained UNPC Model from: {CHECKPOINT_PATH} ...\")\n\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH)\n    model = AutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT_PATH)\n    print(\"Successfully loaded UNPC model weights!\")\nexcept OSError as e:\n    print(\"Error loading model. Please check the path in Input panel.\")\n    raise e\n\n# Load TED data\nprint(\"Loading TED data...\")\ntrain_ted = load_dataset_from_text(\n    os.path.join(DATA_DIR, \"train_ted.en\"), \n    os.path.join(DATA_DIR, \"train_ted.zh\")\n)\ndev_ted = load_dataset_from_text(\n    os.path.join(DATA_DIR, \"dev_ted.en\"), \n    os.path.join(DATA_DIR, \"dev_ted.zh\")\n)\nprint(f\"TED Train size: {len(train_ted)}\")\n\nprint(\"Preprocessing TED data...\")\ntokenized_train_ted = train_ted.map(preprocess_function, batched=True)\ntokenized_dev_ted = dev_ted.map(preprocess_function, batched=True)\n\n# Set training arguments (TED Domain Adaptation)\nargs = Seq2SeqTrainingArguments(\n    output_dir=OUTPUT_DIR,\n    eval_strategy=\"epoch\",      \n    save_strategy=\"epoch\",\n    learning_rate=2e-5,        \n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,         \n    predict_with_generate=True,\n    fp16=True,\n    logging_steps=50,        \n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_train_ted,\n    eval_dataset=tokenized_dev_ted,\n    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Starting TED Domain Adaptation...\")\ntrainer.train()\n\ntrainer.save_model(OUTPUT_DIR)\nprint(f\"TED Training Complete! Model saved to {OUTPUT_DIR}\")\n\n\nshutil.make_archive(\"/kaggle/working/ted_model_backup\", 'zip', OUTPUT_DIR)\nprint(\"Backup created: ted_model_backup.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T10:30:55.966823Z","iopub.execute_input":"2026-01-08T10:30:55.967119Z","iopub.status.idle":"2026-01-08T11:01:58.891142Z","shell.execute_reply.started":"2026-01-08T10:30:55.967090Z","shell.execute_reply":"2026-01-08T11:01:58.890411Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef03524e7b55494f9ef442c65b1500ac"}},"metadata":{}},{"name":"stdout","text":"Loading Pre-trained UNPC Model from: /kaggle/input/final-unpc-model ...\nSuccessfully loaded UNPC model weights!\nLoading TED data...\nTED Train size: 50000\nPreprocessing TED data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6887612642934f2ab77f8a50fe34e1ea"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700d530240514329a883180484069311"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_55/1163181332.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"name":"stdout","text":"Starting TED Domain Adaptation...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4689/4689 28:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.547800</td>\n      <td>2.380073</td>\n      <td>18.333715</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.368200</td>\n      <td>2.317173</td>\n      <td>18.197097</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.279800</td>\n      <td>2.298169</td>\n      <td>17.701789</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"TED Training Complete! Model saved to /kaggle/working/final_ted_model\nBackup created: ted_model_backup.zip\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#import os\n#import torch\n#import numpy as np\n#import pandas as pd\n#from datasets import Dataset\n#from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n#import evaluate\n#from comet import download_model, load_from_checkpoint\n\n\nDATA_DIR = \"/kaggle/input/final-data/processed\"\nTATOEBA_FILE_PATH = \"/kaggle/input/tatoeba-test/tatoeba-test-v2023-09-26.eng-zho.txt\"\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nMODELS = {\n    \"Baseline\": \"Helsinki-NLP/opus-mt-en-mul\",\n    \"Model A (UNPC)\": \"/kaggle/input/final-unpc-model\", \n    \"Model B (TED)\":  \"/kaggle/input/trained-ted-model\"   \n}\n\nTEST_SETS = {\n    \"TED Test\": (\"pair\", (\"test_ted.en\", \"test_ted.zh\")),\n    \"Tatoeba\":  (\"single\", TATOEBA_FILE_PATH) \n}\n\n# Initialize Metrics\n# BLEU & chrF \nmetric_bleu = evaluate.load(\"sacrebleu\")\nmetric_chrf = evaluate.load(\"chrf\")\n\n# COMET \nprint(\"Downloading COMET model...\")\ntry:\n    comet_model_path = download_model(\"Unbabel/wmt20-comet-da\")\n    comet_model = load_from_checkpoint(comet_model_path)\n    use_comet = True\nexcept Exception as e:\n    print(f\"COMET load failed: {e}. Skipping COMET.\")\n    use_comet = False\n\n\n# Load standard pair files (TED/UNPC)\ndef load_pair_data(src_file, tgt_file):\n    with open(os.path.join(DATA_DIR, src_file), 'r') as f: src = [l.strip() for l in f]\n    with open(os.path.join(DATA_DIR, tgt_file), 'r') as f: tgt = [l.strip() for l in f]\n    return src, tgt\n\n# Load Tatoeba single file\ndef load_tatoeba_file(file_path):\n    print(f\"Reading Tatoeba from: {file_path}\")\n    srcs = []\n    tgts = []\n    \n    if not os.path.exists(file_path):\n        print(f\"Error: File not found at {file_path}\")\n        return [], []\n\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            parts = line.strip().split('\\t')\n            \n            if len(parts) >= 4 and 'Hans' in parts[1]:\n                srcs.append(parts[2])\n                tgts.append(parts[3])\n                \n    print(f\"Loaded {len(srcs)} sentences from Tatoeba (Simplified Chinese only).\")\n    return srcs, tgts\n\n# Core Evaluation Function\ndef evaluate_model(model_path, model_name, test_name, src_text, tgt_text):\n    print(f\"Evaluating {model_name} on {test_name}...\")\n    \n    # Load model\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(DEVICE)\n    \n    # Generate Translations\n    translations = []\n    batch_size = 16 \n    prefix = \">>zho<< \"\n    \n    for i in range(0, len(src_text), batch_size):\n        batch = [prefix + s for s in src_text[i:i+batch_size]]\n        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(DEVICE)\n        \n        with torch.no_grad():\n            generated = model.generate(**inputs, max_length=128)\n        \n        decoded = tokenizer.batch_decode(generated, skip_special_tokens=True)\n        translations.extend(decoded)\n    \n    # Calculate BLEU (tokenized)\n    bleu_score = metric_bleu.compute(predictions=translations, references=tgt_text, tokenize='zh')['score']\n    \n    # Calculate chrF (character level)\n    chrf_score = metric_chrf.compute(predictions=translations, references=tgt_text)['score']\n    \n    # Calculate COMET\n    comet_score = 0\n    if use_comet:\n        comet_data = [{\"src\": s, \"mt\": m, \"ref\": r} for s, m, r in zip(src_text, translations, tgt_text)]\n\n        try:\n            comet_out = comet_model.predict(comet_data, batch_size=8, gpus=1)\n            comet_score = comet_out.system_score \n        except Exception as e:\n            print(f\"COMET calculation error: {e}\")\n    \n    # Print Examples\n    print(f\"Examples for {model_name}:\")\n    for i in range(min(3, len(src_text))): \n        print(f\"   Src: {src_text[i]}\")\n        print(f\"   Ref: {tgt_text[i]}\")\n        print(f\"   Hyp: {translations[i]}\")\n        print(\"-\" * 20)\n\n    return {\n        \"BLEU\": round(bleu_score, 2),\n        \"chrF\": round(chrf_score, 2),\n        \"COMET\": round(comet_score, 4)\n    }\n\n# Main Loop\nfinal_results = []\n\nfor model_name, model_path in MODELS.items():\n    for test_name, (load_type, file_info) in TEST_SETS.items():\n        \n        if load_type == \"pair\":\n            src, tgt = load_pair_data(file_info[0], file_info[1])\n        elif load_type == \"single\":\n            src, tgt = load_tatoeba_file(file_info)\n        \n        if len(src) > 0:\n            scores = evaluate_model(model_path, model_name, test_name, src, tgt)\n            \n            res = {\"Model\": model_name, \"Test Set\": test_name}\n            res.update(scores)\n            final_results.append(res)\n            \n            torch.cuda.empty_cache()\n\ndf = pd.DataFrame(final_results)\nprint(\"FINAL RESULTS TABLE:\")\nprint(df.to_markdown(index=False))\n\ndf.to_csv(\"evaluation_results.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T11:37:14.948322Z","iopub.execute_input":"2026-01-08T11:37:14.948898Z","iopub.status.idle":"2026-01-08T11:50:58.226275Z","shell.execute_reply.started":"2026-01-08T11:37:14.948861Z","shell.execute_reply":"2026-01-08T11:50:58.225482Z"}},"outputs":[{"name":"stdout","text":"Downloading COMET model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfed0429fab74e06afba8f4b49bd865d"}},"metadata":{}},{"name":"stderr","text":"INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../root/.cache/huggingface/hub/models--Unbabel--wmt20-comet-da/snapshots/87819f4d6d4f17e0d1752cc9e0ccfa2064997219/checkpoints/model.ckpt`\n/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Baseline on TED Test...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/310M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39c3c9a6f5d4877a08878f4bb2abb0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35454593600c46818f76caccc5c9233f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/310M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24dff552f1841ed967eca7123fef89a"}},"metadata":{}},{"name":"stderr","text":"INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 125/125 [00:20<00:00,  6.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Baseline:\n   Src: So Europe is not just an example now to emulate; it's an enemy to fight and to resist.\n   Ref: 因此欧洲从之前的榜样变成了当时的竞争者 变成了需要反抗和斗争的敌人\n   Hyp: 所以欧洲不是现在的一个例子,是战斗和反抗的敌人。\n--------------------\n   Src: I do want to talk -- the absolute icing on this cemetery cake is the Barricini family mausoleum nearby.\n   Ref: 但我想说 -- 公墓所用蛋糕的糖衣部分 是在Barricini 家族的陵墓附近.\n   Hyp: 我要谈谈 -- 对这场葬礼蛋糕的绝对发射是巴里西尼家属的大麻\n--------------------\n   Src: It's a parabolic Scheffler solar cooker.\n   Ref: 这是一个抛物形的全自动太阳能炊具。\n   Hyp: 這是個太阳的小子\n--------------------\nReading Tatoeba from: /kaggle/input/tatoeba-test/tatoeba-test-v2023-09-26.eng-zho.txt\nLoaded 5526 sentences from Tatoeba (Simplified Chinese only).\nEvaluating Baseline on Tatoeba...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 691/691 [01:07<00:00, 10.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Baseline:\n   Src: Tom got drunk with his friends in the park.\n   Ref: 汤姆和他的朋友们在公园喝醉了\n   Hyp: 托姆和他在公园里的朋友喝醉了\n--------------------\n   Src: Tom isn't going to give me that.\n   Ref: 汤姆不会同意的\n   Hyp: 托姆不会给我那个\n--------------------\n   Src: 2016 was the hottest year on record.\n   Ref: 2016年是有记录以来最热的一年。\n   Hyp: 2016年是记录上最热的年。\n--------------------\nEvaluating Model A (UNPC) on TED Test...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 125/125 [00:22<00:00,  5.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Model A (UNPC):\n   Src: So Europe is not just an example now to emulate; it's an enemy to fight and to resist.\n   Ref: 因此欧洲从之前的榜样变成了当时的竞争者 变成了需要反抗和斗争的敌人\n   Hyp: 因此,欧洲现在不仅是一个模拟的例子。 战斗和抵抗是一个敌人。\n--------------------\n   Src: I do want to talk -- the absolute icing on this cemetery cake is the Barricini family mausoleum nearby.\n   Ref: 但我想说 -- 公墓所用蛋糕的糖衣部分 是在Barricini 家族的陵墓附近.\n   Hyp: 我想谈话 -- -- 这个墓地蛋糕的绝对混乱是附近的Barricini家庭毛象。\n--------------------\n   Src: It's a parabolic Scheffler solar cooker.\n   Ref: 这是一个抛物形的全自动太阳能炊具。\n   Hyp: 这是一名太阳性厨师。\n--------------------\nReading Tatoeba from: /kaggle/input/tatoeba-test/tatoeba-test-v2023-09-26.eng-zho.txt\nLoaded 5526 sentences from Tatoeba (Simplified Chinese only).\nEvaluating Model A (UNPC) on Tatoeba...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 691/691 [01:10<00:00,  9.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Model A (UNPC):\n   Src: Tom got drunk with his friends in the park.\n   Ref: 汤姆和他的朋友们在公园喝醉了\n   Hyp: Tom与他在公园的朋友喝醉了。\n--------------------\n   Src: Tom isn't going to give me that.\n   Ref: 汤姆不会同意的\n   Hyp: 托姆不会给我这样。\n--------------------\n   Src: 2016 was the hottest year on record.\n   Ref: 2016年是有记录以来最热的一年。\n   Hyp: 2016年是记录最热的年份。\n--------------------\nEvaluating Model B (TED) on TED Test...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 125/125 [00:23<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Model B (TED):\n   Src: So Europe is not just an example now to emulate; it's an enemy to fight and to resist.\n   Ref: 因此欧洲从之前的榜样变成了当时的竞争者 变成了需要反抗和斗争的敌人\n   Hyp: 所以欧洲不仅仅是一个模拟的例子, 而是一种战斗和抵抗的敌人。\n--------------------\n   Src: I do want to talk -- the absolute icing on this cemetery cake is the Barricini family mausoleum nearby.\n   Ref: 但我想说 -- 公墓所用蛋糕的糖衣部分 是在Barricini 家族的陵墓附近.\n   Hyp: 我想说话—— 这个墓地蛋糕上的绝对兴奋 是巴里西尼的家属毛索里姆附近。\n--------------------\n   Src: It's a parabolic Scheffler solar cooker.\n   Ref: 这是一个抛物形的全自动太阳能炊具。\n   Hyp: 它是一名模拟性的Scheffler太阳能厨师。\n--------------------\nReading Tatoeba from: /kaggle/input/tatoeba-test/tatoeba-test-v2023-09-26.eng-zho.txt\nLoaded 5526 sentences from Tatoeba (Simplified Chinese only).\nEvaluating Model B (TED) on Tatoeba...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 691/691 [01:16<00:00,  9.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Examples for Model B (TED):\n   Src: Tom got drunk with his friends in the park.\n   Ref: 汤姆和他的朋友们在公园喝醉了\n   Hyp: 汤姆和他在公园里的朋友喝醉了。\n--------------------\n   Src: Tom isn't going to give me that.\n   Ref: 汤姆不会同意的\n   Hyp: (笑声) 汤姆不会给我这件事。\n--------------------\n   Src: 2016 was the hottest year on record.\n   Ref: 2016年是有记录以来最热的一年。\n   Hyp: 2016年是记录上最热的一年。\n--------------------\nFINAL RESULTS TABLE:\n| Model          | Test Set   |   BLEU |   chrF |   COMET |\n|:---------------|:-----------|-------:|-------:|--------:|\n| Baseline       | TED Test   |  14.19 |  17.83 | -0.3222 |\n| Baseline       | Tatoeba    |  20.87 |  18.57 |  0.2637 |\n| Model A (UNPC) | TED Test   |  16.07 |  18.92 | -0.1693 |\n| Model A (UNPC) | Tatoeba    |  19.48 |  18.99 |  0.3034 |\n| Model B (TED)  | TED Test   |  21.01 |  24.72 |  0.0018 |\n| Model B (TED)  | Tatoeba    |  21.07 |  21.83 |  0.2977 |\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import time\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport evaluate\n\n# Use the best model\nMODEL_PATH = \"/kaggle/input/trained-ted-model\" \nDATA_DIR = \"/kaggle/input/final-data/processed\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef load_data(src_file, tgt_file):\n    with open(f\"{DATA_DIR}/{src_file}\", 'r') as f: src = [l.strip() for l in f]\n    with open(f\"{DATA_DIR}/{tgt_file}\", 'r') as f: tgt = [l.strip() for l in f]\n    return src, tgt\n\nsrc_text, tgt_text = load_data(\"test_ted.en\", \"test_ted.zh\")\n\n\nprint(f\"Loading Model from {MODEL_PATH}...\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(DEVICE)\nmetric_bleu = evaluate.load(\"sacrebleu\")\n\nstrategies = {\n    \"Greedy Search\": {\n        \"num_beams\": 1, \n        \"do_sample\": False\n    },\n    \"Beam Search (k=5)\": {\n        \"num_beams\": 5, \n        \"early_stopping\": True\n    },\n    \"Beam Search (k=10)\": {\n        \"num_beams\": 10, \n        \"early_stopping\": True\n    }\n}\n\nresults = []\nbatch_size = 16\nprefix = \">>zho<< \"\n\nprint(\"Starting Decoding Strategy Experiment...\")\n\nfor name, params in strategies.items():\n    print(f\"Testing Strategy: {name} ...\")\n    \n    start_time = time.time()\n    translations = []\n    \n    for i in range(0, len(src_text), batch_size):\n        batch = [prefix + s for s in src_text[i:i+batch_size]]\n        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(DEVICE)\n        \n        with torch.no_grad():\n        \n            generated = model.generate(**inputs, max_length=128, **params)\n        \n        decoded = tokenizer.batch_decode(generated, skip_special_tokens=True)\n        translations.extend(decoded)\n        \n    end_time = time.time()\n    duration = end_time - start_time\n    \n    bleu = metric_bleu.compute(predictions=translations, references=tgt_text, tokenize='zh')['score']\n    \n    results.append({\n        \"Strategy\": name,\n        \"BLEU\": round(bleu, 2),\n        \"Time (s)\": round(duration, 2),\n        \"Sec/Sample\": round(duration / len(src_text), 4)\n    })\n\ndf = pd.DataFrame(results)\nprint(\"DECODING STRATEGY COMPARISON:\")\nprint(df.to_markdown(index=False))\n\ndf.to_csv(\"decoding_experiment.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:51:06.718160Z","iopub.execute_input":"2026-01-08T16:51:06.718692Z","iopub.status.idle":"2026-01-08T16:55:02.689448Z","shell.execute_reply.started":"2026-01-08T16:51:06.718661Z","shell.execute_reply":"2026-01-08T16:55:02.688563Z"}},"outputs":[{"name":"stdout","text":"Loading Model from /kaggle/input/trained-ted-model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45fc93c949cb4e68930ddbbcdbf405bd"}},"metadata":{}},{"name":"stdout","text":"Starting Decoding Strategy Experiment...\nTesting Strategy: Greedy Search ...\nTesting Strategy: Beam Search (k=5) ...\nTesting Strategy: Beam Search (k=10) ...\nDECODING STRATEGY COMPARISON:\n| Strategy           |   BLEU |   Time (s) |   Sec/Sample |\n|:-------------------|-------:|-----------:|-------------:|\n| Greedy Search      |  20.56 |      33.28 |       0.0333 |\n| Beam Search (k=5)  |  20.95 |      68.65 |       0.0686 |\n| Beam Search (k=10) |  20.91 |     125.53 |       0.1255 |\n","output_type":"stream"}],"execution_count":3}]}