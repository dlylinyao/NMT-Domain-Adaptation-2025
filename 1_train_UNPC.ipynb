{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T11:42:16.190615Z",
     "iopub.status.busy": "2026-01-07T11:42:16.190372Z",
     "iopub.status.idle": "2026-01-07T11:42:26.985333Z",
     "shell.execute_reply": "2026-01-07T11:42:26.984708Z",
     "shell.execute_reply.started": "2026-01-07T11:42:16.190591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: /kaggle/input/final-data/processed\n",
      "\n",
      "======== Analyzing: UNPC Cleaned (Train) ========\n",
      "1. Line Count (Sentence Pairs): 462483\n",
      "2. Avg Length (Source EN): 19.45 words, 123.11 chars\n",
      "   Avg Length (Target ZH): 2.81 words, 49.63 chars\n",
      "3. Vocabulary Size (Unique Tokens): Source=372300, Target=669711\n",
      "4. Avg Length Ratio (Src/Tgt Char Ratio): 2.42\n",
      "5. Calculating Character Entropy...\n",
      "   Source Entropy: 4.8487\n",
      "   Target Entropy: 8.5990\n",
      "\n",
      "----- Random Sample (Qualitative Check) -----\n",
      "[39781] EN: GPS works in very logical steps; each of the orbiting satellites beams a continuous radio signal to Earth, which is received by a GPS receiver in order to derive distances by measuring the travel time of the radio signals.\n",
      "      ZH: 13. 全球定位系统工作步骤非常富有逻辑性；每一在轨卫星向地球发射连续无线电信号，该信号被全球定位系统接收机接收，以便通过量测无线电信号的传播时间得出距离。\n",
      "[96625] EN: 56. At the invitation of the Chairman, Ms. Mardach Miguel (Women for Peace and Justice for Vieques) took a seat at the petitioners &apos; table.\n",
      "      ZH: 56. 在主席的邀请下，Mardach Miguel女士（妇女促进别克斯和平与正义）在请愿者桌前就座。\n",
      "[52380] EN: Annex. Resource mobilization and allocation target table for Africa\n",
      "      ZH: 附件. 非洲资源调动和分配目标表(1997-2001年) 18\n",
      "[195687] EN: 9. Some members asked whether the Committee would have data for 2002 when it considered the next scale in 2003.\n",
      "      ZH: 9． 一些成员问委员会2003年审议下一个分摊比额表时是否会有2002年的数据。\n",
      "[190051] EN: F. Adult education and literacy 187 - 188 43\n",
      "      ZH: F. 成人教育和扫盲 187 - 188 49\n",
      "[154349] EN: However, certain conduct, characterized by some as religious, is not in fact valid in human or in moral terms.\n",
      "      ZH: 然而，由部分人称为宗教性的某些行为，实际上用人的标准或道德标准衡量是不能成立的。\n",
      "[246286] EN: 185. In the case of Judge Teranishi, the Special Rapporteur considers that the course of action taken against him may have been justified on the facts.\n",
      "      ZH: 185. 关于Teranishi法官一案，特别报告员认为，根据事实来看，对他采取的惩诫行动可能是有道理的。\n",
      "[277297] EN: With the year 2000 now only 27 months away, we are still far from that goal.\n",
      "      ZH: 现在距离2000年只剩下27个月了,但是我们距离这一目标还很远。\n",
      "[456262] EN: Article 2, paragraph 2: The role of the tribunal, after its formation, in determining ( &quot; tahdid &quot; ) the subject matter of the dispute requires interpretation.\n",
      "      ZH: 第2条第2款：对仲裁法庭组成之后在确定( &quot; tahdid &quot; )争端主题事项方面的作用需要作出解释。\n",
      "[8922] EN: Charged to wrong object code.\n",
      "      ZH: 记入错误的支出用途代号。\n",
      "[432849] EN: Under START II, deployed strategic nuclear warheads will be reduced by two thirds to 3,000-3,500.\n",
      "      ZH: 根据第二阶段裁武条约，已部署的战略核弹头将裁减2/3，减至3 000至3 500枚。\n",
      "[207838] EN: 37. Mr. Al-Malki (Qatar) said that women elected to parliament would have exactly the same political rights as men.\n",
      "      ZH: 37. Al-Malki先生(卡塔尔)说,当选为议员的妇女具有同男人完全一样的政治权利。\n",
      "[349241] EN: Members: Cuba, India, Portugal (on behalf of the European Union; Bulgaria, the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Malta, Poland, Romania, Slovakia and Slovenia aligned themselves with the statement)\n",
      "      ZH: 成员：古巴、印度、葡萄牙(代表欧洲联盟；保加利亚、捷克共和国、爱沙尼亚、匈牙利、拉脱维亚、立陶宛、马耳他、波兰、罗马尼亚、斯洛伐克和斯洛文尼亚表示支持该发言)\n",
      "[228217] EN: Mr. Stephanopoulos stated that the United States military strike against Al-Shifa Pharmaceutical Factory in Khartoum has been part of a Clinton administration &quot; Wag the Dog &quot; scenario.\n",
      "      ZH: 斯特凡诺普洛斯先生说,美国对喀土穆Al-Shifa制药厂的军事突击是克林顿政府内部有人 &quot; 摇狗尾巴逢迎 &quot; 情节的一部分。\n",
      "[392949] EN: Unfortunately, this has not been the case and we stress the huge danger of that.\n",
      "      ZH: 不幸的是，情况并非如此，我们要强调指出这种情况的巨大危险性。\n",
      "[324622] EN: 11. On 3 November 1993, the Human Rights Committee decided that the communication was admissible in so far as it may raise issues under articles 6 and 7 of the Covenant.\n",
      "      ZH: 11. 1993年11月3日,人权事务委员会裁定鉴于来文可能会在《盟约》第6条和第7条下产生一些问题所以是可以受理的。\n",
      "[166912] EN: The General Assembly decides to defer consideration of the item entitled “Joint Inspection Unit” to the main part of its fifty-fourth session.\n",
      "      ZH: 大会决定将题为 &quot; 联合检查组 &quot; 的审议推迟到第五十四届会议的主要会期会议。\n",
      "[156404] EN: Apportionment: $186,597,000; expenditure: $151,411,500; variance: $35,185,500\n",
      "      ZH: 分配数：186 597 000美元；支出：151 411 500美元；差额：35 185 500美元\n",
      "[1984] EN: Other claimants seek compensation for the value of vessels or, in the case of one claimant, a yacht damaged by Iraqi forces in Kuwait.\n",
      "      ZH: 187. 另一些索赔人要求赔偿船舶的价值，有一个索赔人要求赔偿在科威特被伊拉克部队损坏的一艘游艇。\n",
      "[101283] EN: Uzbekistan had a tradition of highly accomplished women, and an impressive heritage of women active in the labour force.\n",
      "      ZH: 乌兹别克斯坦妇女在传统上有着非常高的成就，而且引人注目的是，该国妇女在劳动大军中历来很活跃。\n",
      "\n",
      "======== Analyzing: TED Cleaned (Train) ========\n",
      "1. Line Count (Sentence Pairs): 50000\n",
      "2. Avg Length (Source EN): 15.77 words, 87.08 chars\n",
      "   Avg Length (Target ZH): 2.35 words, 35.95 chars\n",
      "3. Vocabulary Size (Unique Tokens): Source=65426, Target=109915\n",
      "4. Avg Length Ratio (Src/Tgt Char Ratio): 2.44\n",
      "5. Calculating Character Entropy...\n",
      "   Source Entropy: 4.5101\n",
      "   Target Entropy: 8.8156\n",
      "\n",
      "----- Random Sample (Qualitative Check) -----\n",
      "[25832] EN: Thank you, and God bless all of you.\n",
      "      ZH: 谢谢各位，愿上帝赐福大家。\n",
      "[21959] EN: And they're out there!\n",
      "      ZH: 而这些英雄就在那里！\n",
      "[27911] EN: But apart from that, everything else goes through contractions of muscles.\n",
      "      ZH: 不过除了那个以外 所有事情都是由肌肉的收缩来办到的\n",
      "[1060] EN: They are new but trying to look old.\n",
      "      ZH: 他们都是新的,但试图显得旧些.\n",
      "[14193] EN: Nadia Al-Sakkaf: See Yemen through my eyes\n",
      "      ZH: Nadia Al-Sakkaf ：我看也门\n",
      "[35365] EN: I lived the high-life.\n",
      "      ZH: 我过着高品质的生活。\n",
      "[29201] EN: They go to the clinics, because they want to cure their immediate symptoms, and they will find somebody to talk to and discuss these issues and talk about what is burdening them and find solutions, develop their resources, learn tools to solve their family conflicts and gain some confidence in the future.\n",
      "      ZH: 病人会去到诊所里， 因为他们想治愈那些短期的症状， 在那里他们会发现有人可以交流 讨论他们的病情 讨论让他们感到压迫的因素是什么 然后寻找治疗的办法，发掘他们自身潜藏的资源， 学习解决家庭冲突的办法 建立对未来生活的信心。\n",
      "[36814] EN: Remember, we've only been an advanced civilization -- an industrial civilization, if you would -- for 200 years.\n",
      "      ZH: 请记住，我们只不过是拥有进化的文明—— 以及工业文明的物种，如果你算时间那也只有200年。\n",
      "[22473] EN: Now, the term \"information society,\" \"information economy,\" for a very long time has been used as the thing that comes after the industrial revolution. But in fact, for purposes of understanding what's happening today, that's wrong. Because for 150 years, we've had an information economy.\n",
      "      ZH: 虽然\"信息社会,信息经济\"这样的字眼一直都被用来形容工业革命之后涌现出的事物 虽然\"信息社会,信息经济\"这样的字眼一直都被用来形容工业革命之后涌现出的事物 但事实上，为更好地理解当前的情况，这种提法是不对的 因为在过去的150年间，我们一直在信息经济之中，只不过这种信息经济是工业化的\n",
      "[42059] EN: And by the time the movie comes out in May, this will be updated to 2.0 and we will have click-through purchases of offsets.\n",
      "      ZH: 等五月份电影出来的时候,这个版本也会升级到2.0. 更新中包括能够购买碳排放抵消的功能\n",
      "[39316] EN: I, as a cyborg anthropologist, have suddenly said, \"Oh, wow. Now suddenly we're a new form of Homo sapiens, and look at these fascinating cultures, and look at these curious rituals that everybody's doing around this technology.\n",
      "      ZH: 我作为一个半机器人的人类学家， 突然说： “噢， 我们突然就成了一种新新人类。 过来看看这些魅力十足的文化。 过来看看这令人好奇的仪式 每个人都环绕着技术行事。\n",
      "[5919] EN: And he says, \"You know you've achieved perfection in design, not when you have nothing more to add, but when you have nothing more to take away.\"\n",
      "      ZH: 他说道：“你知道你的设计达到完美 不是因为你没有什么可以加上去， 而是当你当你不能再去除些什么的时候。”\n",
      "[34062] EN: And then I measure its altitude.\n",
      "      ZH: 好，让我们记录下它的高度。\n",
      "[10707] EN: Tom Green: That's a 4chan thing.\n",
      "      ZH: Tom Green：这是个4chan特色。\n",
      "[9099] EN: And the first person who gets happy when you do that, you don't do anything for anybody else, but you get happier, you yourself, because your whole perception broadens and you suddenly see the whole world and all of the people in it.\n",
      "      ZH: 当你那样想的时候，第一个快乐起来的人是你， 你还没有为其他人做任何事，你就会变得更快乐，你自己， 因为你的整个观念开阔了， 你突然看到整个世界和它其中所有的人。\n",
      "[49355] EN: But what else could I offer her?\n",
      "      ZH: 但我又能为她做些什么？\n",
      "[43346] EN: You saw it with the recent economic crash, where bad things happen in the economy -- bad for everybody, for much of the world.\n",
      "      ZH: 你可以看到在近期的金融危机， 经济发生了很多不好的事， 对每个人都不好，对世界都不好。\n",
      "[37379] EN: And I only stumbled on this because I was living in Malé, in Maldives for long enough for it to percolate into my brain that something rather special was going on.\n",
      "      ZH: 我是因为住在马累才偶然发现了这点的， 在马尔代夫住了很长时间之后， 我才慢慢地意识到 有一些很特别的事情正在发生。\n",
      "[42337] EN: And by the time you get to the middle, you've got hundreds of people who have contributed only one photo each.\n",
      "      ZH: 当看到这个尾部线条中部时， 你会发现有数百个 仅仅提供了一张照片的摄影者。\n",
      "[44197] EN: The loving soul of the universe.\n",
      "      ZH: 比如是宇宙中关爱的灵魂，\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "POSSIBLE_PATHS = [\n",
    "    \"/kaggle/input/final-data/processed\", \n",
    "    \"/kaggle/input/final-data\", \n",
    "    \"/kaggle/input/processed\"\n",
    "]\n",
    "DATA_DIR = None\n",
    "for p in POSSIBLE_PATHS:\n",
    "    if os.path.exists(p) and \"train_unpc.en\" in os.listdir(p):\n",
    "        DATA_DIR = p\n",
    "        break\n",
    "\n",
    "if not DATA_DIR:\n",
    "    print(\"Data path not found. Please manually modify the DATA_DIR variable!\")\n",
    "else:\n",
    "    print(f\"Data Directory: {DATA_DIR}\")\n",
    "\n",
    "def analyze_corpus(name, src_filename, tgt_filename):\n",
    "    src_path = os.path.join(DATA_DIR, src_filename)\n",
    "    tgt_path = os.path.join(DATA_DIR, tgt_filename)\n",
    "    \n",
    "    if not os.path.exists(src_path) or not os.path.exists(tgt_path):\n",
    "        print(f\"⚠️ Skipping {name}: File not found\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n======== Analyzing: {name} ========\")\n",
    "    \n",
    "    # Statistical variables\n",
    "    src_lines, tgt_lines = [], []\n",
    "    src_lens_char, tgt_lens_char = [], []\n",
    "    src_lens_word, tgt_lens_word = [], []\n",
    "    src_vocab, tgt_vocab = set(), set()\n",
    "    \n",
    "    # Read Source\n",
    "    with open(src_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            l = line.strip()\n",
    "            src_lines.append(l)\n",
    "            src_lens_char.append(len(l))\n",
    "            words = l.split() # Simple whitespace tokenization\n",
    "            src_lens_word.append(len(words))\n",
    "            src_vocab.update(words)\n",
    "\n",
    "    # Read Target\n",
    "    with open(tgt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            l = line.strip()\n",
    "            tgt_lines.append(l)\n",
    "            tgt_lens_char.append(len(l))\n",
    "            words = l.split()\n",
    "            tgt_lens_word.append(len(words))\n",
    "            tgt_vocab.update(words)\n",
    "\n",
    "    count = len(src_lines)\n",
    "    print(f\"1. Line Count (Sentence Pairs): {count}\")\n",
    "    \n",
    "    avg_src_w = sum(src_lens_word) / count\n",
    "    avg_tgt_w = sum(tgt_lens_word) / count\n",
    "    avg_src_c = sum(src_lens_char) / count\n",
    "    avg_tgt_c = sum(tgt_lens_char) / count\n",
    "    \n",
    "    print(f\"2. Avg Length (Source EN): {avg_src_w:.2f} words, {avg_src_c:.2f} chars\")\n",
    "    print(f\"   Avg Length (Target ZH): {avg_tgt_w:.2f} words, {avg_tgt_c:.2f} chars\")\n",
    "\n",
    "    print(f\"3. Vocabulary Size (Unique Tokens): Source={len(src_vocab)}, Target={len(tgt_vocab)}\")\n",
    "\n",
    "    ratios = []\n",
    "    for sl, tl in zip(src_lens_char, tgt_lens_char):\n",
    "        if tl == 0: continue\n",
    "        ratios.append(sl / tl)\n",
    "    if ratios:\n",
    "        avg_ratio = sum(ratios) / len(ratios)\n",
    "        print(f\"4. Avg Length Ratio (Src/Tgt Char Ratio): {avg_ratio:.2f}\")\n",
    "\n",
    "    def get_entropy(text_list):\n",
    "        full_text = \"\".join(text_list)\n",
    "        if not full_text: return 0\n",
    "        counts = Counter(full_text)\n",
    "        total = len(full_text)\n",
    "        ent = 0\n",
    "        for cnt in counts.values():\n",
    "            p = cnt / total\n",
    "            ent -= p * math.log2(p)\n",
    "        return ent\n",
    "\n",
    "    print(\"5. Calculating Character Entropy...\")\n",
    "    print(f\"   Source Entropy: {get_entropy(src_lines):.4f}\")\n",
    "    print(f\"   Target Entropy: {get_entropy(tgt_lines):.4f}\")\n",
    "\n",
    "    print(\"\\n----- Random Sample (Qualitative Check) -----\")\n",
    "    indices = random.sample(range(count), min(20, count))\n",
    "    for idx in indices:\n",
    "        print(f\"[{idx}] EN: {src_lines[idx]}\")\n",
    "        print(f\"      ZH: {tgt_lines[idx]}\")\n",
    "\n",
    "if DATA_DIR:\n",
    "    # Analyze UNPC Cleaned\n",
    "    analyze_corpus(\"UNPC Cleaned (Train)\", \"train_unpc.en\", \"train_unpc.zh\")\n",
    "    \n",
    "    # Analyze TED Cleaned\n",
    "    analyze_corpus(\"TED Cleaned (Train)\", \"train_ted.en\", \"train_ted.zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T11:42:49.610063Z",
     "iopub.status.busy": "2026-01-07T11:42:49.609584Z",
     "iopub.status.idle": "2026-01-07T11:42:59.041034Z",
     "shell.execute_reply": "2026-01-07T11:42:59.040164Z",
     "shell.execute_reply.started": "2026-01-07T11:42:49.610030Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hGPU Available: True\n",
      "Current Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers[torch] datasets sacrebleu evaluate sentencepiece\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Warning: You are using CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-07T11:43:22.367599Z",
     "iopub.status.busy": "2026-01-07T11:43:22.367078Z",
     "iopub.status.idle": "2026-01-07T11:43:33.400785Z",
     "shell.execute_reply": "2026-01-07T11:43:33.400113Z",
     "shell.execute_reply.started": "2026-01-07T11:43:22.367566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path confirmed: /kaggle/input/final-data/processed\n",
      "Loading model vocabulary: Helsinki-NLP/opus-mt-en-mul...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd505733e98e45eb9b9698dffa2a20c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3cfcc58d444aa3b4e701a3a2f8e285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5642c6354e9c4c4f9f6d915b374ab9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/790k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac49bfdf21742e09080823dc46269fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/707k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f34587b0e14e98a8b5d402822e0a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Analyzing: English Train Set (train_unpc.en)\n",
      "  [Sample 1] Text: a 1999 data are provisional....\n",
      "  [Sample 1] Tokens: ['▁a', '▁1999', '▁data', '▁are', '▁provisional', '.']\n",
      "  [Sample 2] Text: Recalling its resolution 49/251 of 20 July 1995 on...\n",
      "  [Sample 2] Tokens: ['▁Recalling', '▁its', '▁resolution', '▁49', '/25', '1', '▁of', '▁20', '▁July', '▁1995', '▁on', '▁the', '▁financing', '▁of', '▁the', '▁Tribunal', '▁and', '▁its', '▁subsequent', '▁resolutions', '▁thereon', ',', '▁the', '▁latest', '▁of', '▁which', '▁was', '▁resolution', '▁53', '/21', '3', '▁of', '▁18', '▁December', '▁1998,']\n",
      " English Train Set Average Length: 27.84 tokens\n",
      "\n",
      " Analyzing: Chinese Train Set (train_unpc.zh)\n",
      "  [Sample 1] Text: a 1999年数据为暂定数据。...\n",
      "  [Sample 1] Tokens: ['▁a', '▁1999', '年', '数', '据', '为', '暂', '定', '数', '据', '。']\n",
      "  [Sample 2] Text: 回顾其1995年7月20日关于该法庭经费筹措的第49/251号决议及其后各项有关决议,最近的一项是1...\n",
      "  [Sample 2] Tokens: ['▁', '回', '顾', '其', '1995', '年', '7', '月', '20', '日', '关', '于', '该', '法', '庭', '经', '费', '筹措', '的', '第', '49', '/25', '1', '号', '决议', '及', '其', '后', '各', '项', '有', '关', '决议', ',', '最近', '的', '一', '项', '是', '1998', '年', '12', '月', '18', '日', '第', '53', '/21', '3', '号', '决议', ',']\n",
      " Chinese Train Set Average Length: 38.84 tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer Analysis & Data Path Verification\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "POSSIBLE_PATHS = [\n",
    "    \"/kaggle/input/final-data/processed\", \n",
    "    \"/kaggle/input/final-data\",          \n",
    "    \"/kaggle/input/processed\"            \n",
    "]\n",
    "\n",
    "DATA_DIR = None\n",
    "for p in POSSIBLE_PATHS:\n",
    "    if os.path.exists(p) and \"train_unpc.en\" in os.listdir(p):\n",
    "        DATA_DIR = p\n",
    "        break\n",
    "\n",
    "if not DATA_DIR:\n",
    "    print(\"Data not found! Please check the Data panel on the right, copy the 'processed' folder path, and update the paths above.\")\n",
    "else:\n",
    "    print(f\"Data path confirmed: {DATA_DIR}\")\n",
    "\n",
    "MODEL_CHECKPOINT = \"Helsinki-NLP/opus-mt-en-mul\"\n",
    "\n",
    "# Load Tokenizer\n",
    "print(f\"Loading model vocabulary: {MODEL_CHECKPOINT}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "def analyze_file(filename, label):\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    print(f\"\\n Analyzing: {label} ({filename})\")\n",
    "    \n",
    "    lengths = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 10000: break \n",
    "            tokens = tokenizer.tokenize(line.strip())\n",
    "            lengths.append(len(tokens))\n",
    "            \n",
    "            if i < 2:\n",
    "                print(f\"  [Sample {i+1}] Text: {line.strip()[:50]}...\")\n",
    "                print(f\"  [Sample {i+1}] Tokens: {tokens}\")\n",
    "\n",
    "    print(f\" {label} Average Length: {np.mean(lengths):.2f} tokens\")\n",
    "\n",
    "# Run Analysis\n",
    "if DATA_DIR:\n",
    "    analyze_file(\"train_unpc.en\", \"English Train Set\")\n",
    "    analyze_file(\"train_unpc.zh\", \"Chinese Train Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T13:55:50.512056Z",
     "iopub.status.busy": "2026-01-07T13:55:50.511687Z",
     "iopub.status.idle": "2026-01-07T17:29:29.880327Z",
     "shell.execute_reply": "2026-01-07T17:29:29.879358Z",
     "shell.execute_reply.started": "2026-01-07T13:55:50.512025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Preprocessing data (Tokenizing)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa270c1b16aa4ef69a25ab1b82199d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462483 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfe54a5dd2d4789942a8f651be96969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/2469563598.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training UNPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
      "\tsave_steps: 500 (from args) != 1000 (from trainer_state.json)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43359' max='43359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43359/43359 3:30:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.231500</td>\n",
       "      <td>1.116636</td>\n",
       "      <td>45.534853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>1.048062</td>\n",
       "      <td>46.401930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.079200</td>\n",
       "      <td>1.028858</td>\n",
       "      <td>46.380594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[64109]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Model saved to: /kaggle/working/final_unpc_model\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np \n",
    "\n",
    "# Core Configuration \n",
    "SOURCE_PREFIX = \">>zho<< \" \n",
    "BATCH_SIZE = 16         \n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3       \n",
    "OUTPUT_DIR = \"/kaggle/working/unpc_model\"\n",
    "\n",
    "def load_dataset_from_text(src_path, tgt_path):\n",
    "    with open(src_path, \"r\", encoding=\"utf-8\") as fs, open(tgt_path, \"r\", encoding=\"utf-8\") as ft:\n",
    "        return Dataset.from_dict({\"source\": [l.strip() for l in fs], \"target\": [l.strip() for l in ft]})\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "train_ds = load_dataset_from_text(os.path.join(DATA_DIR, \"train_unpc.en\"), os.path.join(DATA_DIR, \"train_unpc.zh\"))\n",
    "dev_ds = load_dataset_from_text(os.path.join(DATA_DIR, \"dev_unpc.en\"), os.path.join(DATA_DIR, \"dev_unpc.zh\"))\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_function(examples):\n",
    "    inputs = [SOURCE_PREFIX + ex for ex in examples[\"source\"]]\n",
    "    targets = examples[\"target\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "print(\"Preprocessing data (Tokenizing)...\")\n",
    "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
    "tokenized_dev = dev_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "# Training Settings\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple): preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",    \n",
    "    # eval_steps=500,             \n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=1000,            \n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,         \n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    predict_with_generate=True, \n",
    "    fp16=True,                  \n",
    "    logging_steps=100,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start Training\n",
    "print(\"Starting training UNPC...\")\n",
    "#trainer.train()\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Save final model\n",
    "final_path = \"/kaggle/working/final_unpc_model\"\n",
    "trainer.save_model(final_path)\n",
    "print(f\"Training complete! Model saved to: {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T17:31:04.103170Z",
     "iopub.status.busy": "2026-01-07T17:31:04.102766Z",
     "iopub.status.idle": "2026-01-07T17:31:21.982120Z",
     "shell.execute_reply": "2026-01-07T17:31:21.981293Z",
     "shell.execute_reply.started": "2026-01-07T17:31:04.103133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing model folder, please wait...\n",
      "Compression complete! File created: /kaggle/working/unpc_model_backup.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "model_path = \"/kaggle/working/final_unpc_model\"\n",
    "output_filename = \"/kaggle/working/unpc_model_backup\"\n",
    "\n",
    "print(\"Compressing model folder, please wait...\")\n",
    "shutil.make_archive(output_filename, 'zip', model_path)\n",
    "print(f\"Compression complete! File created: {output_filename}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9206452,
     "sourceId": 14414569,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
